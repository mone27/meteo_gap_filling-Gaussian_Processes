{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e25b75aa-51b1-4980-97f5-68df5c3eceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cda543e-9b92-4a60-943a-9e2e3d6a5c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| default_exp learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31ca6d73-c7bc-49af-a142-dbbaf6402c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f74180-fccb-4f9f-91b5-7250f48d5dc8",
   "metadata": {},
   "source": [
    "# GPFA Learner\n",
    "\n",
    "> Utilities to train and visualize a GPFA model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe43aefc-a8d5-4a01-8fca-0e5819186d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.distributions import MultivariateNormal \n",
    "\n",
    "import gpytorch\n",
    "from gpfa_imputation.gpfa import *\n",
    "from collections import namedtuple\n",
    "\n",
    "from fastcore.foundation import *\n",
    "from fastprogress.fastprogress import progress_bar, master_bar\n",
    "from fastcore.foundation import patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48b6e03-df45-4e08-b68a-3674fbf4a13c",
   "metadata": {},
   "source": [
    "The first thing that we need is a Learner object to keep track of:\n",
    "\n",
    "- input data, output data\n",
    "- model\n",
    "- likelihood\n",
    "\n",
    "and that has methods to help with:\n",
    "\n",
    "- training\n",
    "- prediction \n",
    "- visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f18d28-1fb7-496a-a2c5-c959b20be768",
   "metadata": {},
   "source": [
    "The first thing we need is a training loop, just wrap in a function the example one from GPyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d4b790-2027-496d-b159-c2b816dc59ae",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1e5bdb-d292-45fe-b059-30f39684b133",
   "metadata": {},
   "source": [
    "The different variables in the can have pretty different values so we normalize so they are more comparable. Have numbers between 0 and 1 should also help with the computation accuracy.\n",
    "\n",
    "One additional complexity is the need to backtransform not only the mean but also the standard deviation.\n",
    "\n",
    "So we need a but of math\n",
    "\n",
    "$$x_{norm} = \\frac{x - \\mu_x}{\\sigma_x}$$\n",
    "then\n",
    "$$x = x_{norm}\\sigma_x + \\mu_x $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fc5156-2fa2-4d69-9bb9-5b0a0010cfd7",
   "metadata": {},
   "source": [
    "using properties of Guassian distributions ^[https://cs.nyu.edu/~roweis/notes/gaussid.pdf eq. 4a]\n",
    "\n",
    "$$p(x_{norm}) = \\mathcal{N}(\\mu_{norm}, \\sigma^2_{norm})$$\n",
    "\n",
    "$$p(x) = \\mathcal{N}(\\sigma_x\\mu_{norm} + \\mu_x, \\sigma^2_x \\sigma^2_{norm})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f871a188-4af6-43c6-ac0e-1ca69dfa802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def normalize(x: Tensor # up to 2D tensor \n",
    "             ) -> tuple[Tensor, Tensor, Tensor]: # Tuple of `x_norm`, `x_mean` and `x_std`\n",
    "    \"Normalize (substract mean and divide by standard deviation) input tensor\"\n",
    "    x_mean = x.mean(axis=0)\n",
    "    x_std = x.std(axis=0)\n",
    "\n",
    "    return ((x - x_mean) / x_std), x_mean, x_std \n",
    "\n",
    "def reverse_normalize(x_norm, # Normalized array\n",
    "                      x_mean, # mean used in normalization\n",
    "                      x_std   # std dev used in normalization\n",
    "                      ) -> Tensor:       # Array after reversing normalization\n",
    "    return x_norm * x_std + x_mean\n",
    "\n",
    "def reverse_normalize_std(x_std_norm, # Normalized array of standard deviations\n",
    "                      x_std   # std dev used in normalization\n",
    "                      ) -> Tensor:       # Array after reversing normalization\n",
    "    return x_std_norm * x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8797019d-24de-40b4-8dda-0addb1e92a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(20).reshape(-1,2)\n",
    "test_close(x, reverse_normalize(*normalize(x)))\n",
    "# need to add test for reverse_normalize_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8ed76b-c01b-475f-9494-10c54d4d0047",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c0bef3a-0b73-4352-8a9e-7291aaae760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GPFALearner():\n",
    "    def __init__(self,\n",
    "                 X: Tensor, # (n_features * n_obs) Multivariate time series\n",
    "                 T: Tensor = None # (n_obs) Vector of time of observations.\n",
    "                 # If none each observation is considered to be at the same distance\n",
    "                ):\n",
    "        self.prepare_X(X)\n",
    "        if T is None: self.default_time(X)\n",
    "        else: self.T = T\n",
    "        \n",
    "        self.likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "        latent_kernel = gpytorch.kernels.RBFKernel()\n",
    "        self.model = GPFA(self.T, self.X, self.likelihood, self.n_features, latent_kernel)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def prepare_X(self, X):\n",
    "        X, self.x_mean, self.x_std = normalize(X)\n",
    "        # flatten Matrix to vector\n",
    "        self.X = X.reshape(-1) \n",
    "        self.n_features = X.shape[1]\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def default_time(self, X):\n",
    "        self.T = torch.arange(X.shape[0])\n",
    "        \n",
    "    \n",
    "    def train(self, n_iter=100, lr=0.1):\n",
    "        # need to enable training mode\n",
    "        self.model.train()\n",
    "        self.likelihood.train()\n",
    "        \n",
    "        # Use the adam optimizer\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr) \n",
    "        \n",
    "        self.losses = torch.zeros(n_iter)\n",
    "        # \"Loss\" for GPs - the marginal log likelihood\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(self.likelihood, self.model)\n",
    "        self.pb = master_bar([1])\n",
    "        for _ in self.pb:\n",
    "            for i in progress_bar(range(n_iter), parent=self.pb):\n",
    "                # Zero gradients from previous iteration\n",
    "                optimizer.zero_grad()\n",
    "                # Output from model\n",
    "                output = self.model(self.T)\n",
    "                # Calc loss and backprop gradients\n",
    "                loss = -mll(output, self.X)\n",
    "                self.losses[i] = loss.detach()\n",
    "                loss.backward()\n",
    "                self.printer(i)\n",
    "\n",
    "                optimizer.step()\n",
    "        \n",
    "        \n",
    "    def printer(self, i):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9105fe73-aa6d-4232-a1f3-24e8276a008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "T = torch.arange(0,6)\n",
    "\n",
    "X = torch.vstack([(torch.arange(0,3, dtype=torch.float32) + 2 + i) * i for i in T]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90ae1f7d-510d-4b69-88c5-a797bb5c2fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.],\n",
       "        [ 3.,  4.,  5.],\n",
       "        [ 8., 10., 12.],\n",
       "        [15., 18., 21.],\n",
       "        [24., 28., 32.],\n",
       "        [35., 40., 45.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a63fd700-c0af-4ad4-8e52-4c5d6a339212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l for learner\n",
    "l = GPFALearner(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57c9acea-2c30-42c7-9a66-10535dbf21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(T, l.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d31067ba-ff73-4e57-be57-f5d34efdef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with explicit time\n",
    "test_eq(T, GPFALearner(X, T).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b198aad5-7fc9-4665-8823-a28d42a74ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(l.n_features, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04726f27-5861-4f00-881d-f15935e05f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0590, -1.0955, -1.1236, -0.8347, -0.8326, -0.8305, -0.4610, -0.4382,\n",
       "        -0.4201,  0.0623,  0.0876,  0.1075,  0.7350,  0.7449,  0.7523,  1.5573,\n",
       "         1.5337,  1.5145])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69a69e95-19a1-405e-9998-d97920b5dc44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/anaconda3/envs/data-science/lib/python3.10/site-packages/gpytorch/lazy/triangular_lazy_tensor.py:136: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2183.)\n",
      "  res = torch.triangular_solve(right_tensor, self.evaluate(), upper=self.upper).solution\n",
      "/home/simone/anaconda3/envs/data-science/lib/python3.10/site-packages/torch/autograd/__init__.py:173: UserWarning: operator() profile_node %840 : int[] = prim::profile_ivalue(%838)\n",
      " does not have profile information (Triggered internally at  ../torch/csrc/jit/codegen/cuda/graph_fuser.cpp:104.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "l.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66b38db4-2eba-4009-b272-d6054980262b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.3442,  1.3034,  1.2644,  1.2289,  1.1978,  1.1685,  1.1362,  1.1000,\n",
       "         1.0615,  1.0225,  0.9837,  0.9453,  0.9072,  0.8689,  0.8301,  0.7906,\n",
       "         0.7506,  0.7100,  0.6689,  0.6275,  0.5859,  0.5442,  0.5025,  0.4608,\n",
       "         0.4190,  0.3772,  0.3353,  0.2932,  0.2510,  0.2086,  0.1662,  0.1237,\n",
       "         0.0813,  0.0389, -0.0033, -0.0455, -0.0876, -0.1296, -0.1714, -0.2132,\n",
       "        -0.2548, -0.2962, -0.3375, -0.3786, -0.4196, -0.4603, -0.5008, -0.5410,\n",
       "        -0.5810, -0.6207, -0.6601, -0.6990, -0.7343, -0.7640, -0.8089, -0.8364,\n",
       "        -0.8857, -0.9075, -0.9574, -0.9789, -1.0242, -1.0492, -1.0886, -1.1164,\n",
       "        -1.1515, -1.1772, -1.2128, -1.2350, -1.2700, -1.2861, -1.3172, -1.3314,\n",
       "        -1.3617, -1.3904, -1.4003, -1.4268, -1.4382, -1.4574, -1.4849, -1.4873,\n",
       "        -1.5002, -1.5141, -1.5112, -1.5356, -1.5542, -1.5486, -1.5625, -1.5695,\n",
       "        -1.5620, -1.5779, -1.5880, -1.5860, -1.6030, -1.6040, -1.5996, -1.6096,\n",
       "        -1.6022, -1.5983, -1.6107, -1.6174])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa919f20-cc8f-47c7-b35e-12e57b7486f4",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "\n",
    "add a function to get predictions from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "681f4ef6-9f6b-44d9-877b-1095b222bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@torch.no_grad() # don't calc gradients on predictions\n",
    "@patch()\n",
    "def predict_raw(self: GPFALearner, T):\n",
    "    self.model.eval()\n",
    "    self.likelihood.eval()\n",
    "    return self.likelihood(self.model(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57ed0643-1ce3-40ac-bb5b-59534c2c6c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/anaconda3/envs/data-science/lib/python3.10/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultivariateNormal(loc: torch.Size([18]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_out = l.predict_raw(T)\n",
    "raw_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14e256c-f331-4508-9ace-d1b161528fd7",
   "metadata": {},
   "source": [
    "the model prediction is a distribution with `len(T)*n_features` dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a050f2-0aa0-4e0a-8fb7-869397feadc9",
   "metadata": {},
   "source": [
    "which is in the in the wrong shape and need to be rescaled after the normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2540a9d5-7fab-4722-bb71-8356f01d69cd",
   "metadata": {},
   "source": [
    "Also we don't need th full distribution but only the mean and stddev for each variable at every time step\n",
    "\n",
    "And we can \"fix\" the shape by transforming back to a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ebaf0b9-1f07-4bc4-8719-a0c7047e203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_stddev = raw_out.stddev.reshape(-1, l.n_features)\n",
    "raw_mean = raw_out.mean.reshape(-1, l.n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a07d9468-642a-4c7e-b40f-203680003159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0250, 0.0198, 0.0224],\n",
       "        [0.0242, 0.0187, 0.0214],\n",
       "        [0.0239, 0.0183, 0.0211],\n",
       "        [0.0239, 0.0183, 0.0211],\n",
       "        [0.0242, 0.0187, 0.0214],\n",
       "        [0.0250, 0.0198, 0.0224]], grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47b23a4c-2da7-4bda-887c-29ef751600b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "NormParam = namedtuple(\"NormalParameters\", [\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da3af212-6cd8-4e60-8648-7562469bb7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO document this function better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d04c2f8-7d02-4ada-8b4b-d98cf29d9b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@torch.no_grad()\n",
    "@patch\n",
    "def predict(self: GPFALearner, T):\n",
    "    raw_out = self.predict_raw(T)\n",
    "    raw_std = raw_out.stddev.reshape(-1, self.n_features)\n",
    "    raw_mean = raw_out.mean.reshape(-1, self.n_features)\n",
    "    \n",
    "    pred_mean = reverse_normalize(raw_mean, self.x_mean, self.x_std)\n",
    "    pred_std = reverse_normalize_std(raw_std, self.x_std)\n",
    "    # detach to avoid that gradients are calculated on results\n",
    "    return NormParam(pred_mean.detach(), pred_std.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46eea5e6-89a6-4a71-bf56-e8fce29eab54",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[0, 3]' is invalid for input of size 18",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(self, T)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;129m@patch\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m: GPFALearner, T):\n\u001b[1;32m      5\u001b[0m     raw_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_raw(T)\n\u001b[0;32m----> 6\u001b[0m     raw_std \u001b[38;5;241m=\u001b[39m \u001b[43mraw_out\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstddev\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     raw_mean \u001b[38;5;241m=\u001b[39m raw_out\u001b[38;5;241m.\u001b[39mmean\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features)\n\u001b[1;32m      9\u001b[0m     pred_mean \u001b[38;5;241m=\u001b[39m reverse_normalize(raw_mean, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_mean, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_std)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[0, 3]' is invalid for input of size 18"
     ]
    }
   ],
   "source": [
    "l.predict(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0784d70-8220-4372-99e9-485647e68c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = l.predict(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e977b09d-703f-4152-ad05-78273a6d750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01055e42-da8f-481d-9f62-2f8e83987adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.std.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0965c418-ca0f-40d9-a53a-fecb5fd3bb68",
   "metadata": {},
   "source": [
    "### Check learning is working"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb33da4a-ca64-489d-bddc-eff1bdef3dbc",
   "metadata": {},
   "source": [
    "The idea is to use the current model to generate a dataset, that can be for sure modelled using a GPFA (because is the output of GPFA) and then train another model and see if the parameters converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7530f0b-ba2c-409b-ac15-04dde1ec9213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dummy GPFA with 3 features\n",
    "Lt = GPFALearner(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c72f6-6073-4451-ac94-becc940978e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = {\n",
    "   \"Lambda\": torch.tensor([-1, 0.3, .8]).reshape(Lt.n_features, -1),\n",
    "   \"psi\": torch.tensor([1e-5, 5e-5, 2e-5]),\n",
    "   \"latent_kernel.lengthscale\": torch.tensor(5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75348565-ae93-442e-926e-882619bf3c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lt.model.covar_module.initialize(**test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa81d68-083b-4904-b54f-2768078945d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_X = Lt.predict(T).mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5665123d-a870-42f2-8f19-a82caae617da",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = GPFALearner(target_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fba72dc-5a1a-4955-826c-88d574196996",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18af534f-0c2b-4024-bd28-61ca0c3ac004",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2.predict(T).mean - target_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e62c4f0-39e9-4f57-bcc8-3bbdda35b175",
   "metadata": {},
   "source": [
    "they seems pretty small numbers, so the model is working! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9aab33-6ea7-4c07-8de1-50c136763970",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lambda:\\n\", l2.model.covar_module.Lambda.detach())\n",
    "\n",
    "print(\"psi: \", l2.model.covar_module.psi.detach())\n",
    "\n",
    "print(\"lengthscale:\", l2.model.covar_module.latent_kernel.lengthscale.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919e6d87-368e-4456-86b2-6adf60a8585d",
   "metadata": {},
   "source": [
    "## Printer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe30200-7597-4051-a408-32cc4c40b323",
   "metadata": {},
   "source": [
    "This methods get called at each training iterator to show the progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670e4cb0-d021-497b-9dff-a097d5cb1158",
   "metadata": {},
   "source": [
    "we want to extract all the parameters from the model. If there is a contraint tranfrom the parameter to get the correct value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59e9bf6-219f-47e0-b284-e85825d17d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameter_value(name, param, constraint):\n",
    "    if constraint is not None:\n",
    "        value = constraint.transform(param.data.detach())\n",
    "        name = name.replace(\"raw_\", \"\") # parameter is not raw anymore\n",
    "    else:\n",
    "        value = param.data.detach()\n",
    "    return (name, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5e188e-8470-4946-8a38-ad0a0df60c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"covar_module.psi\"\n",
    "test_eq(l.model.covar_module.psi.detach(), get_parameter_value(name, l.model.covar_module.raw_psi_diag, l.model.covar_module.raw_psi_diag_constraint)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1126cee-f8f7-4997-9bb7-be1446613999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_first_item(tensor):\n",
    "    if tensor.dim() > 0:\n",
    "        return tensor_to_first_item(tensor[0])\n",
    "    return tensor.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6baa6a-97e7-4db4-89f9-ea562ffd8101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_parameter(name, value):\n",
    "    value = tensor_to_first_item(value)\n",
    "    name = name.split(\".\")[-1] # get only last part of name\n",
    "    return f\"{name}: {value:.3f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab63ab0-354a-479a-b27c-e75df7e2cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_formatted_params(self: GPFALearner):\n",
    "    return \", \".join([\n",
    "        format_parameter(*get_parameter_value(name, value, constraint))\n",
    "        for name, value, constraint in\n",
    "        self.model.named_parameters_and_constraints()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f2243e-4934-49ad-aa49-760d8ce02622",
   "metadata": {},
   "outputs": [],
   "source": [
    "l.get_formatted_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a11ce9-80f7-48fa-a6c0-496ab0307ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is not really working at the moment, but it's not important\n",
    "@patch\n",
    "def plot_loss(self: GPFALearner, i_iter):\n",
    "    if i_iter ==0: return\n",
    "    x = torch.arange(0, i_iter)\n",
    "    y = self.losses[:i_iter]\n",
    "    plot_data = [[x, y]]\n",
    "    self.pb.update_graph(plot_data)\n",
    "    \n",
    "    x_bounds = [x.min(), x.max()+1]\n",
    "    y_bounds = [y.min(), y.max()]\n",
    "    self.pb.names = [\"Training loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e81958-97c3-49dd-ba5d-718898e91df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def printer(self: GPFALearner, i_iter):\n",
    "\n",
    "    if i_iter%10 == 0:\n",
    "        update_str = f\"loss: {self.losses[i_iter].item():.3f}, \" + self.get_formatted_params()\n",
    "        #self.plot_loss(i_iter)\n",
    "    \n",
    "    #self.pb.write(update_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ada474-9681-4f2a-9024-a517c285e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "l.train(lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64935ea1-89df-456a-8c7d-a3037320cbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c344f-67f8-49fb-a833-730978420f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(l.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58580804-365d-447a-9a5e-3463f4846b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
