{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8bf0b28-3066-47f0-a9ec-17f7dbfd56e9",
   "metadata": {},
   "source": [
    "# Imputation time series\n",
    "\n",
    "> Impute time series using GPFA Leaner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e93a35-c0f5-40f1-b111-7d58a767574f",
   "metadata": {},
   "source": [
    "the goal of this notebook is to be able to:\n",
    "\n",
    "- take a timeseries that contains gaps\n",
    "- train a GPFA Learner using the available data\n",
    "- impute the gap, by using the predictions of the learner\n",
    "- to improve the imputation by conditioning the distribution on the other observation at the same time stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abcc8b0e-193c-4819-8a27-dafe166f4dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9b18213-e77e-46e4-8aaf-b45f2754cf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| default_exp imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8e6a941-58c3-4cba-aa4f-54b0a2d41a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpfa_imputation.learner import *\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e796831-6f23-47df-a479-d83f7b842ed6",
   "metadata": {},
   "source": [
    "## Fake data \n",
    "\n",
    "generate some fake data in order to test the imputation\n",
    "\n",
    "What is does is:\n",
    "- take a function to generate the \"true\" latent\n",
    "- use some random coefficient to generate all the N features\n",
    "- add some random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0cf4c98-0527-492b-ac76-3f2ae76435ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GPFAFakeData:\n",
    "    def __init__(self,\n",
    "                    n_features: int,\n",
    "                    n_obs: int,\n",
    "                    latent_func = torch.sin, # Functions used to generate the true latent:\n",
    "                    noise_std = .2\n",
    "                ):\n",
    "        \n",
    "        self.n_features, self.n_obs = n_features, n_obs\n",
    "        self.T = torch.arange(n_obs)\n",
    "        \n",
    "        self.latent = latent_func(self.T)\n",
    "        \n",
    "        self.Lambda = torch.rand(n_features, 1)\n",
    "        \n",
    "        self.exact_X = (self.Lambda * self.latent).T\n",
    "        \n",
    "        self.X =  self.exact_X + torch.normal(0., noise_std, size = (n_obs, n_features)) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb6f6e7e-7013-4824-8089-46d3da8f8c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = GPFAFakeData(3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "111ec241-d642-4e3e-9de3-fd69cd3bc81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1093, -0.0152,  0.2280],\n",
       "        [ 0.3716,  0.3290,  1.1037],\n",
       "        [ 0.3686, -0.0628,  0.8996],\n",
       "        [-0.0736, -0.1601, -0.0065],\n",
       "        [-0.4442,  0.1232, -0.6697],\n",
       "        [ 0.0191, -0.1219, -0.6036],\n",
       "        [ 0.1061,  0.1039, -0.3509],\n",
       "        [ 0.2677, -0.1632,  0.7693],\n",
       "        [ 0.5997,  0.1350,  0.8118],\n",
       "        [-0.1333,  0.0640,  0.1867]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a28e5db-3280-4722-876e-0dc36f9fe6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.2660,  0.1493,  0.7628],\n",
       "        [ 0.2875,  0.1613,  0.8243],\n",
       "        [ 0.0446,  0.0250,  0.1279],\n",
       "        [-0.2393, -0.1342, -0.6860],\n",
       "        [-0.3032, -0.1701, -0.8692],\n",
       "        [-0.0883, -0.0496, -0.2533],\n",
       "        [ 0.2077,  0.1165,  0.5955],\n",
       "        [ 0.3128,  0.1755,  0.8968],\n",
       "        [ 0.1303,  0.0731,  0.3736]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.exact_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58580804-365d-447a-9a5e-3463f4846b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc50ec75-1271-40f8-8636-ce45a58105a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
