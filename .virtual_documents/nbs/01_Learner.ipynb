get_ipython().run_line_magic("load_ext", " autoreload")
get_ipython().run_line_magic("autoreload", " 2")


#| hide
#| default_exp learner


from fastcore.test import *


#| export
import torch
from torch import Tensor

import gpytorch
from gpfa_imputation.core import *
from collections import namedtuple

from fastcore.foundation import *
from fastprogress.fastprogress import progress_bar, master_bar
from fastcore.foundation import patch


def normalize(x: Tensor # up to 2D tensor 
             ) -> tuple[Tensor, Tensor, Tensor]: # Tuple of `x_norm`, `x_mean` and `x_std`
    "Normalize (substract mean and divide by standard deviation) input tensor"
    x_mean = x.mean(axis=0)
    x_std = x.std(axis=0)

    return ((x - x_mean) / x_std), x_mean, x_std 


def reverse_normalize(x_norm, # Normalized array
                      x_mean, # mean used in normalization
                      x_std   # std dev used in normalization
                      ) -> Tensor:       # Array after reversing normalization
    return x_norm * x_std + x_mean


def reverse_normalize_std(x_std_norm, # Normalized array of standard deviations
                      x_std   # std dev used in normalization
                      ) -> Tensor:       # Array after reversing normalization
    return x_std_norm * x_std


x = torch.randn(20).reshape(-1,2)
test_close(x, reverse_normalize(*normalize(x)))
# need to add test for reverse_normalize_std


#| export
class GPFALearner():
    def __init__(self, X):
        self.prepare_X(X)
        self.prepare_time(X)
        
        self.likelihood = gpytorch.likelihoods.GaussianLikelihood()
        latent_kernel = gpytorch.kernels.RBFKernel()
        self.model = GPFA(self.T, self.X, self.likelihood, self.n_features, latent_kernel)
        
    @torch.no_grad()
    def prepare_X(self, X):
        X, self.x_mean, self.x_std = normalize(X)
        # flatten Matrix to vector
        self.X = X.reshape(-1) 
        self.n_features = X.shape[1]
        
    @torch.no_grad()
    def prepare_time(self, X):
        self.T = torch.arange(X.shape[0])
        
    
    def train(self, n_iter=100, lr=0.1):
        # need to enable training mode
        self.model.train()
        self.likelihood.train()
        
        # Use the adam optimizer
        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr) 
        
        self.losses = torch.zeros(n_iter)
        # "Loss" for GPs - the marginal log likelihood
        mll = gpytorch.mlls.ExactMarginalLogLikelihood(self.likelihood, self.model)
        self.pb = master_bar([1])
        for _ in self.pb:
            for i in progress_bar(range(n_iter), parent=self.pb):
                # Zero gradients from previous iteration
                optimizer.zero_grad()
                # Output from model
                output = self.model(self.T)
                # Calc loss and backprop gradients
                loss = -mll(output, self.X)
                self.losses[i] = loss.detach()
                loss.backward()
                self.printer(i)

                optimizer.step()
        
        
    def printer(self, i):
        pass
        


# test data
T = torch.arange(0,6)

X = torch.vstack([(torch.arange(0,3, dtype=torch.float32) + 2 + i) * i for i in T]) 


X


# l for learner
l = GPFALearner(X)


test_eq(T, l.T)


test_eq(l.n_features, 3)


l.X


l.train()


l.losses


#| export
@torch.no_grad() # don't calc gradients on predictions
@patch()
def predict_raw(self: GPFALearner, T):
    self.model.eval()
    self.likelihood.eval()
    return self.likelihood(self.model(T))


raw_out = l.predict_raw(T)
raw_out


raw_stddev = raw_out.stddev.reshape(-1, l.n_features)
raw_mean = raw_out.mean.reshape(-1, l.n_features)


raw_stddev


#| export
NormParam = namedtuple("NormalParameters", ["mean", "std"])


#| export
@torch.no_grad()
@patch
def predict(self: GPFALearner, T):
    raw_out = self.predict_raw(T)
    raw_std = raw_out.stddev.reshape(-1, self.n_features)
    raw_mean = raw_out.mean.reshape(-1, self.n_features)
    
    pred_mean = reverse_normalize(raw_mean, self.x_mean, self.x_std)
    pred_std = reverse_normalize_std(raw_std, self.x_std)
    # detach to avoid that gradients are calculated on results
    return NormParam(pred_mean.detach(), pred_std.detach())


l.predict(T)


# create a dummy GPFA with 3 features
Lt = GPFALearner(X)


test_params = {
   "Lambda": torch.tensor([-1, 0.3, .8]).reshape(Lt.n_features, -1),
   "psi": torch.tensor([1e-5, 5e-5, 2e-5]),
   "latent_kernel.lengthscale": torch.tensor(5),
}


Lt.model.covar_module.initialize(**test_params)


target_X = Lt.predict(T).mean


l2 = GPFALearner(target_X)


l2.train()


l2.predict(T).mean - target_X


print("Lambda:\n", l2.model.covar_module.Lambda.detach())

print("psi: ", l2.model.covar_module.psi.detach())

print("lengthscale:", l2.model.covar_module.latent_kernel.lengthscale.item())



def get_parameter_value(name, param, constraint):
    if constraint is not None:
        value = constraint.transform(param.data.detach())
        name = name.replace("raw_", "") # parameter is not raw anymore
    else:
        value = param.data.detach()
    return (name, value)


name = "covar_module.psi"
test_eq(l.model.covar_module.psi.detach(), get_parameter_value(name, l.model.covar_module.raw_psi_diag, l.model.covar_module.raw_psi_diag_constraint)[1])


def tensor_to_first_item(tensor):
    if tensor.dim() > 0:
        return tensor_to_first_item(tensor[0])
    return tensor.item()


def format_parameter(name, value):
    value = tensor_to_first_item(value)
    name = name.split(".")[-1] # get only last part of name
    return f"{name}: {value:.3f}"


#| export
@patch
def get_formatted_params(self: GPFALearner):
    return ", ".join([
        format_parameter(*get_parameter_value(name, value, constraint))
        for name, value, constraint in
        self.model.named_parameters_and_constraints()
    ])


l.get_formatted_params()


@patch
def plot_loss(self: GPFALearner, i_iter):
    if i_iter ==0: return
    x = torch.arange(0, i_iter)
    y = self.losses[:i_iter]
    plot_data = [[x, y]]
    self.pb.update_graph(plot_data)
    
    x_bounds = [x.min(), x.max()+1]
    y_bounds = [y.min(), y.max()]
    self.pb.names = ["Training loss"]


@patch
def printer(self: GPFALearner, i_iter):

    if i_iter%10 == 0:
        update_str = f"loss: {self.losses[i_iter].item():.3f}, " + self.get_formatted_params()
        #self.plot_loss(i_iter)
    
    #self.pb.write(update_str)


l.train(lr = 0.01)


#| hide
from nbdev import nbdev_export
nbdev_export()






