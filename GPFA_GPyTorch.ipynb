{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f421fd58-ff7c-45c4-8d45-b4c070f7bae6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import torch\n",
    "from gpytorch.kernels import RBFKernel\n",
    "from torch.distributions import MultivariateNormal\n",
    "from fastprogress.fastprogress import progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f8c2746-27ff-4af1-889a-26fe8787cc90",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = torch.tensor(\n",
    "    [[1, 3],\n",
    "     [2, 5],\n",
    "     [3, 4]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dccdeaae",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = X.view(-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "25862872",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "T = torch.tensor([1,2,3], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "42f5fb6c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = X - X.mean() # important the mean is assumed to be zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c927fd0e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class GPFAKernel(gpytorch.kernels.Kernel):\n",
    "    has_lengthscale = False\n",
    "    def __init__(self, n_features, latent_kernel, psi = None, **kwargs):\n",
    "        super(GPFAKernel, self).__init__(**kwargs)\n",
    "        \n",
    "        # Number of features in the X for each time step\n",
    "        self.n_features = n_features\n",
    "        self.latent_dims = 1 # More than 1 features is not implemented yet\n",
    "        \n",
    "        self.register_parameter(\n",
    "            name = \"Lambda\",\n",
    "            parameter = torch.nn.Parameter(torch.ones(self.n_features, self.latent_dims)))\n",
    "        \n",
    "        self.latent_kernel = latent_kernel\n",
    "        \n",
    "        self.register_parameter(\n",
    "            name = \"raw_psi_diag\",\n",
    "            parameter = torch.nn.Parameter(torch.zeros(self.n_features) if psi is None else psi)) # check that is is actually working as intented\n",
    "        self.register_constraint(\"raw_psi_diag\", gpytorch.constraints.Positive())\n",
    "    \n",
    "    # now set up the 'actual' parameter\n",
    "    @property\n",
    "    def psi(self):\n",
    "        # when accessing the parameter, apply the constraint transform\n",
    "        return self.raw_psi_diag_constraint.transform(self.raw_psi_diag)\n",
    "\n",
    "    @psi.setter\n",
    "    def psi(self, value):\n",
    "        return self._set_length(value)\n",
    "\n",
    "    def _set_length(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_psi_diag)\n",
    "        # when setting the paramater, transform the actual value to a raw one by applying the inverse transform\n",
    "        self.initialize(raw_length=self.raw_psi_diag_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, t1, t2, diag = False, last_dim_is_batch=False, **params):\n",
    "\n",
    "        # not implemented yet\n",
    "        assert diag is False\n",
    "        assert last_dim_is_batch is False\n",
    "\n",
    "        # taken the number of observations in the input\n",
    "        n_obs = t1.shape[0]\n",
    "\n",
    "        # compute the latent kernel\n",
    "        kT = self.latent_kernel(t1, t2, diag, last_dim_is_batch, **params)\n",
    "        # pre allocate covariance matrix\n",
    "        X = torch.empty(self.n_features * n_obs, self.n_features * n_obs)\n",
    "        \n",
    "        for i in range(n_obs):\n",
    "            for j in range(n_obs):\n",
    "                # since `latent_dim=1 kT[i,j]` is a scalar so the matrix multiplication can be expressed in this way\n",
    "                cov = kT[i,j] * self.Lambda @ self.Lambda.T\n",
    "                # on diagonals add the noise\n",
    "                if i == j: cov += torch.diag(self.psi) \n",
    "                X[i*self.n_features:(i*self.n_features + self.n_features),j*self.n_features:(j*self.n_features+self.n_features)] = cov\n",
    "                \n",
    "        return X\n",
    "    \n",
    "    def num_outputs_per_input(self, x1,x2):\n",
    "        return self.n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8ff3a421",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gp_k = GPFAKernel(n_features=2, latent_kernel=RBFKernel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f706c65f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPFAKernel(\n",
       "  (latent_kernel): RBFKernel(\n",
       "    (raw_lengthscale_constraint): Positive()\n",
       "  )\n",
       "  (raw_psi_diag_constraint): Positive()\n",
       ")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "62b25706",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('latent_kernel',\n",
       "  RBFKernel(\n",
       "    (raw_lengthscale_constraint): Positive()\n",
       "  ))]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gp_k.named_sub_kernels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dbdd6add",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lambda',\n",
       "  Parameter containing:\n",
       "  tensor([[1.],\n",
       "          [1.]], requires_grad=True)),\n",
       " ('raw_psi_diag',\n",
       "  Parameter containing:\n",
       "  tensor([0., 0.], requires_grad=True)),\n",
       " ('latent_kernel.raw_lengthscale',\n",
       "  Parameter containing:\n",
       "  tensor([[0.]], requires_grad=True))]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gp_k.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2a1bdca3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cov = gp_k(T,T).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7a7de9aa",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultivariateNormal(loc: torch.Size([6]), covariance_matrix: torch.Size([6, 6]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultivariateNormal(torch.zeros(cov[0].shape), cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4eeb19",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This is a valid normal distribution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7629fcdc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class GPFAZeroMean(gpytorch.means.Mean):\n",
    "    \"\"\"\n",
    "    Supports no batches\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.n_features = n_features\n",
    "    def forward(self, input, *params):\n",
    "        shape = input.shape[0] * self.n_features\n",
    "        return torch.zeros(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "34835f9e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class GPFA(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(GPFA, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = GPFAZeroMean(2)\n",
    "        self.covar_module = GPFAKernel(2, RBFKernel())\n",
    "\n",
    "    def forward(self, x, **params):\n",
    "        mean_x = self.mean_module(x, **params)\n",
    "        covar_x = self.covar_module(x, **params)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3cb2aabb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = GPFA(T, X, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9f944d84",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPFA(\n",
       "  (likelihood): GaussianLikelihood(\n",
       "    (noise_covar): HomoskedasticNoise(\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (mean_module): GPFAZeroMean()\n",
       "  (covar_module): GPFAKernel(\n",
       "    (latent_kernel): RBFKernel(\n",
       "      (raw_lengthscale_constraint): Positive()\n",
       "    )\n",
       "    (raw_psi_diag_constraint): Positive()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3f4934b6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6931, 1.0000, 0.3532, 0.3532, 0.0156, 0.0156],\n",
       "        [1.0000, 1.6931, 0.3532, 0.3532, 0.0156, 0.0156],\n",
       "        [0.3532, 0.3532, 1.6931, 1.0000, 0.3532, 0.3532],\n",
       "        [0.3532, 0.3532, 1.0000, 1.6931, 0.3532, 0.3532],\n",
       "        [0.0156, 0.0156, 0.3532, 0.3532, 1.6931, 1.0000],\n",
       "        [0.0156, 0.0156, 0.3532, 0.3532, 1.0000, 1.6931]],\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(T).covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "44dcfeca",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "392d6a16",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.covar_module.num_outputs_per_input(T, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "746c4238",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultivariateNormal(loc: torch.Size([6]), covariance_matrix: torch.Size([6, 6]))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultivariateNormal(torch.zeros(cov[0].shape), cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0cee7b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Trying to optimize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ed76b76e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 1.800   lengthscale: 0.693, Lambda: 1.000   noise: 0.693\n",
      "Iter 11/200 - Loss: 1.676   lengthscale: 0.672, Lambda: 0.052   noise: 0.897\n",
      "Iter 21/200 - Loss: 1.684   lengthscale: 0.465, Lambda: -0.268   noise: 0.795\n",
      "Iter 31/200 - Loss: 1.675   lengthscale: 0.314, Lambda: 0.014   noise: 0.854\n",
      "Iter 41/200 - Loss: 1.675   lengthscale: 0.263, Lambda: 0.097   noise: 0.821\n",
      "Iter 51/200 - Loss: 1.668   lengthscale: 0.247, Lambda: -0.023   noise: 0.811\n",
      "Iter 61/200 - Loss: 1.633   lengthscale: 0.261, Lambda: -0.015   noise: 0.577\n",
      "Iter 71/200 - Loss: 1.595   lengthscale: 0.588, Lambda: -0.016   noise: 0.424\n",
      "Iter 81/200 - Loss: 1.500   lengthscale: 1.675, Lambda: 0.058   noise: 0.391\n",
      "Iter 91/200 - Loss: 1.490   lengthscale: 2.590, Lambda: 0.121   noise: 0.336\n",
      "Iter 101/200 - Loss: 1.488   lengthscale: 2.877, Lambda: 0.084   noise: 0.383\n",
      "Iter 111/200 - Loss: 1.486   lengthscale: 2.980, Lambda: 0.037   noise: 0.472\n",
      "Iter 121/200 - Loss: 1.485   lengthscale: 3.134, Lambda: 0.040   noise: 0.481\n",
      "Iter 131/200 - Loss: 1.484   lengthscale: 3.297, Lambda: 0.043   noise: 0.469\n",
      "Iter 141/200 - Loss: 1.483   lengthscale: 3.441, Lambda: 0.033   noise: 0.489\n",
      "Iter 151/200 - Loss: 1.483   lengthscale: 3.593, Lambda: 0.031   noise: 0.494\n",
      "Iter 161/200 - Loss: 1.483   lengthscale: 3.744, Lambda: 0.031   noise: 0.493\n",
      "Iter 171/200 - Loss: 1.482   lengthscale: 3.890, Lambda: 0.028   noise: 0.497\n",
      "Iter 181/200 - Loss: 1.482   lengthscale: 4.033, Lambda: 0.026   noise: 0.498\n",
      "Iter 191/200 - Loss: 1.482   lengthscale: 4.173, Lambda: 0.025   noise: 0.499\n"
     ]
    }
   ],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "training_iter = 200\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "losses = []\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(T)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, X)\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    if i % 10 == 0:\n",
    "        print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f, Lambda: %.3f   noise: %.3f' % (\n",
    "            i + 1, training_iter, loss.item(),\n",
    "            model.covar_module.latent_kernel.lengthscale.item(),\n",
    "            model.covar_module.Lambda.mean().item(),\n",
    "            model.likelihood.noise.item()\n",
    "        ))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce4c669-97cf-429c-8d77-419d020ea1f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2b09b6c8-d30b-4294-8ce8-02b65c9940fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.9126],\n",
       "        [-0.8667]], requires_grad=True)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.covar_module.Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "19132d5f-d1bb-43e5-acf0-4f2e54c0f5fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2549, 0.3439], grad_fn=<SoftplusBackward0>)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.covar_module.psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb0f1af-fef5-40a8-b7ff-ee0c2835f653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "18c41ec0-6fd8-40d1-bd9a-1d504c019033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.,  0., -1.,  2.,  0.,  1.])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c98463",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Hainich data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652c453c-fb3a-4401-8812-c9ff14dfa6b1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### Load data\n",
    "\n",
    "Use 1 month of data from the Hainich site and using a subset of variables\n",
    "\n",
    "Note for simplicity gap filled values are not excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e1cd06ed-fac8-47e6-a1a0-23bc4588e16b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8c64dbb8-6b71-48a4-bde9-37eebe31820b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hai_path = Path(\"FLX_DE-Hai_FLUXNET2015_FULLSET_HH_2000-2012_1-4.csv\")\n",
    "hai_raw = pd.read_csv(\"../MeteoECGapFilling/data\" / hai_path,\n",
    "                      na_values=[\"-9999\", \"-9999.99\"],\n",
    "                      parse_dates=[0, 1],\n",
    "                      nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "593bfcfe-142a-4be6-8a4f-3487ede8d51c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "meteo_vars = {\n",
    "    \"TA_F\": \"TA\",\n",
    "    \"SW_IN_F\": \"SW_IN\",\n",
    "    \"LW_IN_F\": \"LW_IN\",\n",
    "    \"VPD_F\": \"VPD\",\n",
    "    \"PA\": \"PA\"\n",
    "}\n",
    "\n",
    "hai = (hai_raw[\n",
    "           hai_raw.TIMESTAMP_START.between(\n",
    "               datetime(2000, 1, 1),\n",
    "               datetime(2000, 1, 31)\n",
    "           )]\n",
    "       .rename(columns=meteo_vars)\n",
    "       .set_index(\"TIMESTAMP_END\")\n",
    "       .loc[:, meteo_vars.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "15153728-0d7a-4c4a-b4dc-b92c5636f273",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hai[\"time\"] = np.arange(0, len(hai))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c101a405-9343-4812-a149-e41cf1fdf980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA</th>\n",
       "      <th>SW_IN</th>\n",
       "      <th>LW_IN</th>\n",
       "      <th>VPD</th>\n",
       "      <th>PA</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIMESTAMP_END</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:30:00</th>\n",
       "      <td>-0.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>302.475</td>\n",
       "      <td>0.222</td>\n",
       "      <td>96.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 01:00:00</th>\n",
       "      <td>-0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>302.475</td>\n",
       "      <td>0.122</td>\n",
       "      <td>96.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 01:30:00</th>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>301.677</td>\n",
       "      <td>0.090</td>\n",
       "      <td>96.56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 02:00:00</th>\n",
       "      <td>-0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>301.677</td>\n",
       "      <td>0.110</td>\n",
       "      <td>96.56</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 02:30:00</th>\n",
       "      <td>-0.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>301.677</td>\n",
       "      <td>0.102</td>\n",
       "      <td>96.57</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-03 00:00:00</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.274</td>\n",
       "      <td>0.021</td>\n",
       "      <td>97.09</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-03 00:30:00</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.274</td>\n",
       "      <td>0.013</td>\n",
       "      <td>97.09</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-03 01:00:00</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.274</td>\n",
       "      <td>0.004</td>\n",
       "      <td>97.10</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-03 01:30:00</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>304.148</td>\n",
       "      <td>0.000</td>\n",
       "      <td>97.07</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-03 02:00:00</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>304.148</td>\n",
       "      <td>0.000</td>\n",
       "      <td>97.05</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       TA  SW_IN    LW_IN    VPD     PA  time\n",
       "TIMESTAMP_END                                                \n",
       "2000-01-01 00:30:00 -0.60    0.0  302.475  0.222  96.63     0\n",
       "2000-01-01 01:00:00 -0.65    0.0  302.475  0.122  96.58     1\n",
       "2000-01-01 01:30:00 -0.58    0.0  301.677  0.090  96.56     2\n",
       "2000-01-01 02:00:00 -0.51    0.0  301.677  0.110  96.56     3\n",
       "2000-01-01 02:30:00 -0.49    0.0  301.677  0.102  96.57     4\n",
       "...                   ...    ...      ...    ...    ...   ...\n",
       "2000-01-03 00:00:00  0.48    0.0  300.274  0.021  97.09    95\n",
       "2000-01-03 00:30:00  0.41    0.0  300.274  0.013  97.09    96\n",
       "2000-01-03 01:00:00  0.29    0.0  300.274  0.004  97.10    97\n",
       "2000-01-03 01:30:00  0.31    0.0  304.148  0.000  97.07    98\n",
       "2000-01-03 02:00:00  0.42    0.0  304.148  0.000  97.05    99\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5de80fa-f854-4833-8e8a-bb21b7d0a141",
   "metadata": {},
   "source": [
    "The data need to be reshaped to be a vector, where the oberservations for each time step are next to each other. Or in other words you can find the same values every `n_features` elements in the vector.\n",
    "We can visually check that this is the case by comparing with the df above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4a8ebcc3-48ab-411c-b44d-84e192a7f7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.0000e-01,  0.0000e+00,  3.0248e+02,  2.2200e-01,  9.6630e+01,\n",
       "        -6.5000e-01,  0.0000e+00,  3.0248e+02,  1.2200e-01,  9.6580e+01,\n",
       "        -5.8000e-01,  0.0000e+00,  3.0168e+02,  9.0000e-02,  9.6560e+01,\n",
       "        -5.1000e-01,  0.0000e+00,  3.0168e+02,  1.1000e-01,  9.6560e+01,\n",
       "        -4.9000e-01,  0.0000e+00,  3.0168e+02,  1.0200e-01,  9.6570e+01,\n",
       "        -4.0000e-01,  0.0000e+00,  3.0168e+02,  1.1100e-01,  9.6600e+01,\n",
       "        -3.6000e-01,  0.0000e+00,  3.0168e+02,  1.0900e-01,  9.6600e+01,\n",
       "        -3.5000e-01,  0.0000e+00,  3.0168e+02,  1.0700e-01,  9.6590e+01,\n",
       "        -2.8000e-01,  0.0000e+00,  3.0805e+02,  1.2200e-01,  9.6600e+01,\n",
       "        -2.7000e-01,  0.0000e+00,  3.0805e+02,  1.3800e-01,  9.6600e+01])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hai_X = torch.tensor(hai.drop(\"time\", axis=1).to_numpy(), dtype=torch.float32)\n",
    "n_features = hai_X.shape[-1]\n",
    "hai_X[:10, :].reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeb83cb-593e-459e-87df-7ae7239ae47a",
   "metadata": {},
   "source": [
    "For time is easier as we need only to extract the vector of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c143e5bc-bd5c-41f1-b5ab-688ecfdd2694",
   "metadata": {},
   "outputs": [],
   "source": [
    "hai_mean = hai_X.mean(0)\n",
    "hai_std = hai_X.std(0)\n",
    "hai_X = (hai_X - hai_mean)/hai_std\n",
    "hai_X = hai_X.reshape(-1) #flatten input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e7a7ffaf-21bd-4226-ac43-95ddbfc71711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.0561e-06)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hai_X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6ba165a3-c7d9-44a4-acc7-8667c86e0810",
   "metadata": {},
   "outputs": [],
   "source": [
    "hai_T = torch.as_tensor(hai.time.to_numpy(), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0bb4ec16-59a6-40fa-885f-ea0e41e3a03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.7062, -1.6718, -1.6373, -1.6028, -1.5683, -1.5339, -1.4994, -1.4649,\n",
       "        -1.4305, -1.3960, -1.3615, -1.3271, -1.2926, -1.2581, -1.2237, -1.1892,\n",
       "        -1.1547, -1.1202, -1.0858, -1.0513, -1.0168, -0.9824, -0.9479, -0.9134,\n",
       "        -0.8790, -0.8445, -0.8100, -0.7756, -0.7411, -0.7066, -0.6721, -0.6377,\n",
       "        -0.6032, -0.5687, -0.5343, -0.4998, -0.4653, -0.4309, -0.3964, -0.3619,\n",
       "        -0.3275, -0.2930, -0.2585, -0.2240, -0.1896, -0.1551, -0.1206, -0.0862,\n",
       "        -0.0517, -0.0172,  0.0172,  0.0517,  0.0862,  0.1206,  0.1551,  0.1896,\n",
       "         0.2240,  0.2585,  0.2930,  0.3275,  0.3619,  0.3964,  0.4309,  0.4653,\n",
       "         0.4998,  0.5343,  0.5687,  0.6032,  0.6377,  0.6721,  0.7066,  0.7411,\n",
       "         0.7756,  0.8100,  0.8445,  0.8790,  0.9134,  0.9479,  0.9824,  1.0168,\n",
       "         1.0513,  1.0858,  1.1202,  1.1547,  1.1892,  1.2237,  1.2581,  1.2926,\n",
       "         1.3271,  1.3615,  1.3960,  1.4305,  1.4649,  1.4994,  1.5339,  1.5683,\n",
       "         1.6028,  1.6373,  1.6718,  1.7062])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hai_T = (hai_T - hai_T.mean())/hai_T.std() # do we really need to do this?\n",
    "hai_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6c35567e-f558-41cb-b78a-680bfc1cd220",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class GPFA(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, n_features, latent_kernel=RBFKernel()):\n",
    "        super(GPFA, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = GPFAZeroMean(n_features)\n",
    "        self.covar_module = GPFAKernel(n_features, latent_kernel)\n",
    "\n",
    "    def forward(self, x, **params):\n",
    "        mean_x = self.mean_module(x, **params)\n",
    "        covar_x = self.covar_module(x, **params)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "105eaf79-e23c-4feb-aac0-4456cdf3ca9f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# initialize likelihood and model\n",
    "hai_lh = gpytorch.likelihoods.GaussianLikelihood()\n",
    "hai_model = GPFA(hai_T, hai_X, hai_lh, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5bf9e19f-fbaf-42ab-9672-7bd8d9c2488b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultivariateNormal(loc: torch.Size([500]))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hai_model(hai_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "197cfe42-30b6-42a5-8760-4bab6d9ad6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hai_T = hai_T.cuda()\n",
    "#hai_X = hai_X.cuda()\n",
    "#hai_model = hai_model.cuda()\n",
    "#hai_lh = hai_lh.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "50b1ee10-eb08-4293-89f8-6243da28a5d0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='100' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [100/100 03:04&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 01/100 - Loss: 1.424   lengthscale: 0.760, Lambda: 1.000   noise: 0.693\n",
      "Iter 02/100 - Loss: 1.402   lengthscale: 0.814, Lambda: 1.020   noise: 0.644\n",
      "Iter 03/100 - Loss: 1.381   lengthscale: 0.860, Lambda: 1.040   noise: 0.598\n",
      "Iter 04/100 - Loss: 1.360   lengthscale: 0.912, Lambda: 1.057   noise: 0.555\n",
      "Iter 05/100 - Loss: 1.341   lengthscale: 0.964, Lambda: 1.068   noise: 0.513\n",
      "Iter 06/100 - Loss: 1.324   lengthscale: 0.994, Lambda: 1.072   noise: 0.475\n",
      "Iter 07/100 - Loss: 1.309   lengthscale: 0.984, Lambda: 1.075   noise: 0.439\n",
      "Iter 08/100 - Loss: 1.295   lengthscale: 0.953, Lambda: 1.078   noise: 0.405\n",
      "Iter 09/100 - Loss: 1.282   lengthscale: 0.913, Lambda: 1.080   noise: 0.375\n",
      "Iter 10/100 - Loss: 1.271   lengthscale: 0.869, Lambda: 1.080   noise: 0.347\n",
      "Iter 11/100 - Loss: 1.260   lengthscale: 0.823, Lambda: 1.081   noise: 0.322\n",
      "Iter 12/100 - Loss: 1.250   lengthscale: 0.776, Lambda: 1.083   noise: 0.300\n",
      "Iter 13/100 - Loss: 1.239   lengthscale: 0.729, Lambda: 1.083   noise: 0.281\n",
      "Iter 14/100 - Loss: 1.228   lengthscale: 0.683, Lambda: 1.080   noise: 0.265\n",
      "Iter 15/100 - Loss: 1.216   lengthscale: 0.637, Lambda: 1.073   noise: 0.250\n",
      "Iter 16/100 - Loss: 1.204   lengthscale: 0.592, Lambda: 1.062   noise: 0.238\n",
      "Iter 17/100 - Loss: 1.191   lengthscale: 0.549, Lambda: 1.048   noise: 0.227\n",
      "Iter 18/100 - Loss: 1.178   lengthscale: 0.506, Lambda: 1.031   noise: 0.218\n",
      "Iter 19/100 - Loss: 1.165   lengthscale: 0.465, Lambda: 1.012   noise: 0.209\n",
      "Iter 20/100 - Loss: 1.151   lengthscale: 0.426, Lambda: 0.988   noise: 0.201\n",
      "Iter 21/100 - Loss: 1.139   lengthscale: 0.391, Lambda: 0.960   noise: 0.194\n",
      "Iter 22/100 - Loss: 1.126   lengthscale: 0.363, Lambda: 0.925   noise: 0.186\n",
      "Iter 23/100 - Loss: 1.112   lengthscale: 0.342, Lambda: 0.884   noise: 0.179\n",
      "Iter 24/100 - Loss: 1.098   lengthscale: 0.329, Lambda: 0.836   noise: 0.172\n",
      "Iter 25/100 - Loss: 1.082   lengthscale: 0.323, Lambda: 0.779   noise: 0.164\n",
      "Iter 26/100 - Loss: 1.066   lengthscale: 0.322, Lambda: 0.715   noise: 0.156\n",
      "Iter 27/100 - Loss: 1.050   lengthscale: 0.326, Lambda: 0.644   noise: 0.147\n",
      "Iter 28/100 - Loss: 1.036   lengthscale: 0.335, Lambda: 0.568   noise: 0.138\n",
      "Iter 29/100 - Loss: 1.024   lengthscale: 0.347, Lambda: 0.491   noise: 0.129\n",
      "Iter 30/100 - Loss: 1.014   lengthscale: 0.362, Lambda: 0.419   noise: 0.120\n",
      "Iter 31/100 - Loss: 1.007   lengthscale: 0.380, Lambda: 0.356   noise: 0.111\n",
      "Iter 32/100 - Loss: 1.001   lengthscale: 0.401, Lambda: 0.309   noise: 0.103\n",
      "Iter 33/100 - Loss: 0.994   lengthscale: 0.423, Lambda: 0.280   noise: 0.095\n",
      "Iter 34/100 - Loss: 0.986   lengthscale: 0.447, Lambda: 0.268   noise: 0.087\n",
      "Iter 35/100 - Loss: 0.978   lengthscale: 0.473, Lambda: 0.273   noise: 0.080\n",
      "Iter 36/100 - Loss: 0.971   lengthscale: 0.499, Lambda: 0.293   noise: 0.074\n",
      "Iter 37/100 - Loss: 0.966   lengthscale: 0.526, Lambda: 0.322   noise: 0.068\n",
      "Iter 38/100 - Loss: 0.964   lengthscale: 0.554, Lambda: 0.358   noise: 0.063\n",
      "Iter 39/100 - Loss: 0.964   lengthscale: 0.583, Lambda: 0.395   noise: 0.059\n",
      "Iter 40/100 - Loss: 0.966   lengthscale: 0.614, Lambda: 0.430   noise: 0.055\n",
      "Iter 41/100 - Loss: 0.968   lengthscale: 0.645, Lambda: 0.459   noise: 0.052\n",
      "Iter 42/100 - Loss: 0.968   lengthscale: 0.678, Lambda: 0.481   noise: 0.050\n",
      "Iter 43/100 - Loss: 0.968   lengthscale: 0.710, Lambda: 0.494   noise: 0.048\n",
      "Iter 44/100 - Loss: 0.966   lengthscale: 0.742, Lambda: 0.500   noise: 0.047\n",
      "Iter 45/100 - Loss: 0.965   lengthscale: 0.772, Lambda: 0.498   noise: 0.046\n",
      "Iter 46/100 - Loss: 0.963   lengthscale: 0.797, Lambda: 0.492   noise: 0.045\n",
      "Iter 47/100 - Loss: 0.962   lengthscale: 0.818, Lambda: 0.483   noise: 0.045\n",
      "Iter 48/100 - Loss: 0.961   lengthscale: 0.832, Lambda: 0.473   noise: 0.045\n",
      "Iter 49/100 - Loss: 0.959   lengthscale: 0.839, Lambda: 0.465   noise: 0.046\n",
      "Iter 50/100 - Loss: 0.956   lengthscale: 0.839, Lambda: 0.458   noise: 0.046\n",
      "Iter 51/100 - Loss: 0.952   lengthscale: 0.833, Lambda: 0.453   noise: 0.047\n",
      "Iter 52/100 - Loss: 0.949   lengthscale: 0.823, Lambda: 0.451   noise: 0.047\n",
      "Iter 53/100 - Loss: 0.946   lengthscale: 0.809, Lambda: 0.451   noise: 0.047\n",
      "Iter 54/100 - Loss: 0.943   lengthscale: 0.793, Lambda: 0.452   noise: 0.047\n",
      "Iter 55/100 - Loss: 0.941   lengthscale: 0.776, Lambda: 0.455   noise: 0.047\n",
      "Iter 56/100 - Loss: 0.939   lengthscale: 0.759, Lambda: 0.459   noise: 0.046\n",
      "Iter 57/100 - Loss: 0.937   lengthscale: 0.743, Lambda: 0.464   noise: 0.045\n",
      "Iter 58/100 - Loss: 0.935   lengthscale: 0.728, Lambda: 0.470   noise: 0.044\n",
      "Iter 59/100 - Loss: 0.933   lengthscale: 0.713, Lambda: 0.475   noise: 0.042\n",
      "Iter 60/100 - Loss: 0.930   lengthscale: 0.699, Lambda: 0.480   noise: 0.040\n",
      "Iter 61/100 - Loss: 0.927   lengthscale: 0.686, Lambda: 0.485   noise: 0.038\n",
      "Iter 62/100 - Loss: 0.924   lengthscale: 0.672, Lambda: 0.489   noise: 0.036\n",
      "Iter 63/100 - Loss: 0.921   lengthscale: 0.658, Lambda: 0.491   noise: 0.034\n",
      "Iter 64/100 - Loss: 0.917   lengthscale: 0.643, Lambda: 0.493   noise: 0.031\n",
      "Iter 65/100 - Loss: 0.913   lengthscale: 0.626, Lambda: 0.494   noise: 0.029\n",
      "Iter 66/100 - Loss: 0.909   lengthscale: 0.608, Lambda: 0.494   noise: 0.027\n",
      "Iter 67/100 - Loss: 0.905   lengthscale: 0.587, Lambda: 0.494   noise: 0.024\n",
      "Iter 68/100 - Loss: 0.900   lengthscale: 0.566, Lambda: 0.493   noise: 0.022\n",
      "Iter 69/100 - Loss: 0.895   lengthscale: 0.543, Lambda: 0.492   noise: 0.020\n",
      "Iter 70/100 - Loss: 0.891   lengthscale: 0.521, Lambda: 0.492   noise: 0.019\n",
      "Iter 71/100 - Loss: 0.886   lengthscale: 0.500, Lambda: 0.493   noise: 0.017\n",
      "Iter 72/100 - Loss: 0.882   lengthscale: 0.482, Lambda: 0.494   noise: 0.015\n",
      "Iter 73/100 - Loss: 0.879   lengthscale: 0.467, Lambda: 0.496   noise: 0.014\n",
      "Iter 74/100 - Loss: 0.876   lengthscale: 0.456, Lambda: 0.497   noise: 0.013\n",
      "Iter 75/100 - Loss: 0.872   lengthscale: 0.450, Lambda: 0.499   noise: 0.011\n",
      "Iter 76/100 - Loss: 0.870   lengthscale: 0.448, Lambda: 0.500   noise: 0.010\n",
      "Iter 77/100 - Loss: 0.867   lengthscale: 0.450, Lambda: 0.500   noise: 0.009\n",
      "Iter 78/100 - Loss: 0.865   lengthscale: 0.455, Lambda: 0.499   noise: 0.009\n",
      "Iter 79/100 - Loss: 0.864   lengthscale: 0.461, Lambda: 0.497   noise: 0.008\n",
      "Iter 80/100 - Loss: 0.863   lengthscale: 0.468, Lambda: 0.494   noise: 0.007\n",
      "Iter 81/100 - Loss: 0.862   lengthscale: 0.473, Lambda: 0.490   noise: 0.007\n",
      "Iter 82/100 - Loss: 0.862   lengthscale: 0.476, Lambda: 0.485   noise: 0.006\n",
      "Iter 83/100 - Loss: 0.862   lengthscale: 0.475, Lambda: 0.479   noise: 0.006\n",
      "Iter 84/100 - Loss: 0.862   lengthscale: 0.470, Lambda: 0.473   noise: 0.006\n",
      "Iter 85/100 - Loss: 0.862   lengthscale: 0.462, Lambda: 0.467   noise: 0.005\n",
      "Iter 86/100 - Loss: 0.863   lengthscale: 0.453, Lambda: 0.462   noise: 0.005\n",
      "Iter 87/100 - Loss: 0.863   lengthscale: 0.444, Lambda: 0.456   noise: 0.005\n",
      "Iter 88/100 - Loss: 0.863   lengthscale: 0.434, Lambda: 0.452   noise: 0.005\n",
      "Iter 89/100 - Loss: 0.863   lengthscale: 0.423, Lambda: 0.448   noise: 0.005\n",
      "Iter 90/100 - Loss: 0.862   lengthscale: 0.409, Lambda: 0.445   noise: 0.005\n",
      "Iter 91/100 - Loss: 0.857   lengthscale: 0.387, Lambda: 0.442   noise: 0.005\n",
      "Iter 92/100 - Loss: 0.846   lengthscale: 0.356, Lambda: 0.441   noise: 0.005\n",
      "Iter 93/100 - Loss: 0.835   lengthscale: 0.318, Lambda: 0.440   noise: 0.005\n",
      "Iter 94/100 - Loss: 0.830   lengthscale: 0.283, Lambda: 0.439   noise: 0.005\n",
      "Iter 95/100 - Loss: 0.832   lengthscale: 0.253, Lambda: 0.437   noise: 0.005\n",
      "Iter 96/100 - Loss: 0.836   lengthscale: 0.233, Lambda: 0.433   noise: 0.004\n",
      "Iter 97/100 - Loss: 0.837   lengthscale: 0.223, Lambda: 0.428   noise: 0.004\n",
      "Iter 98/100 - Loss: 0.836   lengthscale: 0.220, Lambda: 0.420   noise: 0.004\n",
      "Iter 99/100 - Loss: 0.833   lengthscale: 0.223, Lambda: 0.412   noise: 0.004\n",
      "Iter 100/100 - Loss: 0.828   lengthscale: 0.231, Lambda: 0.401   noise: 0.004\n"
     ]
    }
   ],
   "source": [
    "# TODO convert this to a function\n",
    "# this is for running the notebook in our testing framework\n",
    "training_iter = 100\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "hai_model.train()\n",
    "hai_lh.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(hai_model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "losses = torch.empty(training_iter)\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(hai_lh, hai_model)\n",
    "\n",
    "for i in progress_bar(range(training_iter)):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = hai_model(hai_T)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, hai_X)\n",
    "    losses[i] = loss.detach()\n",
    "    loss.backward()\n",
    "    print('Iter %02d/%d - Loss: %.3f   lengthscale: %.3f, Lambda: %.3f   noise: %.3f' % (\n",
    "        i + 1, training_iter, loss.item(),\n",
    "        hai_model.covar_module.latent_kernel.lengthscale.item(),\n",
    "        hai_model.covar_module.Lambda.mean().item(),\n",
    "        hai_model.likelihood.noise.item()\n",
    "    ))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1513ecc4-3e85-44dc-ba35-46633120494f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.4329],\n",
       "        [ 0.5256],\n",
       "        [-1.4773],\n",
       "        [ 0.7756],\n",
       "        [ 1.6950]], requires_grad=True)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hai_model.covar_module.Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f81269-aac1-49cc-bf30-07b066eecb6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
